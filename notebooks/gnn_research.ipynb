{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abf305a",
   "metadata": {},
   "source": [
    "# AI Travel Planner - GNN Research Notebook\n",
    "\n",
    "This notebook is for researching and developing the Graph Neural Network (GNN) component of the AI Travel Planner.\n",
    "\n",
    "## Objectives\n",
    "1. Build user preference graphs\n",
    "2. Create POI (Point of Interest) relationship graphs\n",
    "3. Implement GNN-based recommendation algorithms\n",
    "4. Test personalization performance\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0498df",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Data\n",
    "\n",
    "Let's create synthetic user and POI data for our research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample users\n",
    "np.random.seed(42)\n",
    "\n",
    "n_users = 1000\n",
    "n_pois = 500\n",
    "\n",
    "# User features\n",
    "users_data = {\n",
    "    'user_id': range(n_users),\n",
    "    'age': np.random.normal(35, 12, n_users).clip(18, 80),\n",
    "    'budget_preference': np.random.choice(['budget', 'mid-range', 'luxury'], n_users, p=[0.3, 0.5, 0.2]),\n",
    "    'travel_style': np.random.choice(['adventure', 'cultural', 'relaxation', 'business'], n_users, p=[0.25, 0.3, 0.3, 0.15]),\n",
    "    'group_size': np.random.poisson(2, n_users).clip(1, 8),\n",
    "    'travel_frequency': np.random.poisson(3, n_users).clip(1, 12),\n",
    "}\n",
    "\n",
    "users_df = pd.DataFrame(users_data)\n",
    "print(f\"Generated {len(users_df)} users\")\n",
    "print(users_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample POIs (Points of Interest)\n",
    "poi_types = ['hotel', 'restaurant', 'attraction', 'activity', 'transport']\n",
    "destinations = ['Paris', 'Tokyo', 'New York', 'London', 'Bangkok', 'Rome', 'Barcelona', 'Mumbai']\n",
    "\n",
    "pois_data = {\n",
    "    'poi_id': range(n_pois),\n",
    "    'type': np.random.choice(poi_types, n_pois),\n",
    "    'destination': np.random.choice(destinations, n_pois),\n",
    "    'price_level': np.random.choice(['$', '$$', '$$$', '$$$$'], n_pois, p=[0.2, 0.4, 0.3, 0.1]),\n",
    "    'rating': np.random.normal(4.0, 0.8, n_pois).clip(1.0, 5.0),\n",
    "    'popularity_score': np.random.exponential(0.3, n_pois).clip(0, 1),\n",
    "}\n",
    "\n",
    "pois_df = pd.DataFrame(pois_data)\n",
    "print(f\"Generated {len(pois_df)} POIs\")\n",
    "print(pois_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcea86",
   "metadata": {},
   "source": [
    "## 2. Build User-User Similarity Graph\n",
    "\n",
    "Create a graph where users are connected based on similarity in preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7fd8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user feature vectors\n",
    "def encode_categorical(df, column, categories):\n",
    "    \"\"\"One-hot encode categorical variables\"\"\"\n",
    "    encoded = pd.get_dummies(df[column], prefix=column)\n",
    "    # Ensure all categories are present\n",
    "    for cat in categories:\n",
    "        col_name = f\"{column}_{cat}\"\n",
    "        if col_name not in encoded.columns:\n",
    "            encoded[col_name] = 0\n",
    "    return encoded\n",
    "\n",
    "# Prepare user features for similarity calculation\n",
    "user_features = users_df[['age', 'group_size', 'travel_frequency']].copy()\n",
    "\n",
    "# Encode categorical features\n",
    "budget_encoded = encode_categorical(users_df, 'budget_preference', ['budget', 'mid-range', 'luxury'])\n",
    "style_encoded = encode_categorical(users_df, 'travel_style', ['adventure', 'cultural', 'relaxation', 'business'])\n",
    "\n",
    "# Combine all features\n",
    "user_features = pd.concat([user_features, budget_encoded, style_encoded], axis=1)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "user_features_scaled = scaler.fit_transform(user_features)\n",
    "\n",
    "print(f\"User feature matrix shape: {user_features_scaled.shape}\")\n",
    "print(f\"Feature names: {list(user_features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce9ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate user similarity matrix\n",
    "user_similarity = cosine_similarity(user_features_scaled)\n",
    "\n",
    "# Create user graph (connect users with similarity > threshold)\n",
    "similarity_threshold = 0.7\n",
    "user_graph = nx.Graph()\n",
    "\n",
    "# Add all users as nodes\n",
    "for i, row in users_df.iterrows():\n",
    "    user_graph.add_node(i, **row.to_dict())\n",
    "\n",
    "# Add edges for similar users\n",
    "edges_added = 0\n",
    "for i in range(n_users):\n",
    "    for j in range(i+1, n_users):\n",
    "        if user_similarity[i, j] > similarity_threshold:\n",
    "            user_graph.add_edge(i, j, weight=user_similarity[i, j])\n",
    "            edges_added += 1\n",
    "\n",
    "print(f\"User graph created:\")\n",
    "print(f\"- Nodes: {user_graph.number_of_nodes()}\")\n",
    "print(f\"- Edges: {user_graph.number_of_edges()}\")\n",
    "print(f\"- Average degree: {2 * user_graph.number_of_edges() / user_graph.number_of_nodes():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd25ddb",
   "metadata": {},
   "source": [
    "## 3. Visualize User Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648cd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a subset of the user graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Take a subgraph for visualization (too many nodes to visualize all)\n",
    "subgraph_nodes = list(user_graph.nodes())[:50]\n",
    "subgraph = user_graph.subgraph(subgraph_nodes)\n",
    "\n",
    "# Create layout\n",
    "pos = nx.spring_layout(subgraph, k=1, iterations=50)\n",
    "\n",
    "# Color nodes by travel style\n",
    "travel_styles = [users_df.loc[node, 'travel_style'] for node in subgraph.nodes()]\n",
    "style_colors = {'adventure': 'red', 'cultural': 'blue', 'relaxation': 'green', 'business': 'orange'}\n",
    "node_colors = [style_colors[style] for style in travel_styles]\n",
    "\n",
    "# Draw graph\n",
    "nx.draw(subgraph, pos, \n",
    "        node_color=node_colors, \n",
    "        node_size=100, \n",
    "        alpha=0.7,\n",
    "        with_labels=False,\n",
    "        edge_color='gray',\n",
    "        width=0.5)\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=color, markersize=10, label=style)\n",
    "                  for style, color in style_colors.items()]\n",
    "plt.legend(handles=legend_elements, title='Travel Style')\n",
    "\n",
    "plt.title('User Similarity Graph (Sample of 50 users)\\nNodes colored by travel style')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d03d7",
   "metadata": {},
   "source": [
    "## 4. Build POI Relationship Graph\n",
    "\n",
    "Create a graph where POIs are connected based on co-occurrence in trips or similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3020dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create POI feature vectors\n",
    "poi_features = pois_df[['rating', 'popularity_score']].copy()\n",
    "\n",
    "# Encode categorical features\n",
    "type_encoded = encode_categorical(pois_df, 'type', poi_types)\n",
    "dest_encoded = encode_categorical(pois_df, 'destination', destinations)\n",
    "price_encoded = encode_categorical(pois_df, 'price_level', ['$', '$$', '$$$', '$$$$'])\n",
    "\n",
    "# Combine features\n",
    "poi_features = pd.concat([poi_features, type_encoded, dest_encoded, price_encoded], axis=1)\n",
    "\n",
    "# Normalize\n",
    "poi_features_scaled = scaler.fit_transform(poi_features)\n",
    "\n",
    "print(f\"POI feature matrix shape: {poi_features_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate POI similarity matrix\n",
    "poi_similarity = cosine_similarity(poi_features_scaled)\n",
    "\n",
    "# Create POI graph\n",
    "poi_threshold = 0.8\n",
    "poi_graph = nx.Graph()\n",
    "\n",
    "# Add POI nodes\n",
    "for i, row in pois_df.iterrows():\n",
    "    poi_graph.add_node(i, **row.to_dict())\n",
    "\n",
    "# Add edges for similar POIs (within same destination)\n",
    "for i in range(n_pois):\n",
    "    for j in range(i+1, n_pois):\n",
    "        # Only connect POIs in the same destination\n",
    "        if (pois_df.iloc[i]['destination'] == pois_df.iloc[j]['destination'] and \n",
    "            poi_similarity[i, j] > poi_threshold):\n",
    "            poi_graph.add_edge(i, j, weight=poi_similarity[i, j])\n",
    "\n",
    "print(f\"POI graph created:\")\n",
    "print(f\"- Nodes: {poi_graph.number_of_nodes()}\")\n",
    "print(f\"- Edges: {poi_graph.number_of_edges()}\")\n",
    "print(f\"- Average degree: {2 * poi_graph.number_of_edges() / poi_graph.number_of_nodes():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7af8b",
   "metadata": {},
   "source": [
    "## 5. Simple GNN Implementation\n",
    "\n",
    "Implement a basic Graph Convolutional Network for user preference prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGCN(nn.Module):\n",
    "    \"\"\"Simple Graph Convolutional Network for recommendation\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super(SimpleGCN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        # First layer\n",
    "        self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        \n",
    "        # Output layer\n",
    "        self.convs.append(GCNConv(hidden_dim, output_dim))\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:  # Don't apply activation to final layer\n",
    "                x = F.relu(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "print(\"✅ GCN model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NetworkX graph to PyTorch Geometric format\n",
    "def networkx_to_pytorch_geometric(graph, node_features):\n",
    "    \"\"\"Convert NetworkX graph to PyTorch Geometric data format\"\"\"\n",
    "    \n",
    "    # Get edge list\n",
    "    edge_list = list(graph.edges())\n",
    "    if not edge_list:\n",
    "        # If no edges, create empty tensor\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Convert features to tensor\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Convert user graph to PyTorch Geometric format\n",
    "user_data = networkx_to_pytorch_geometric(user_graph, user_features_scaled)\n",
    "\n",
    "print(f\"User graph data:\")\n",
    "print(f\"- Node features shape: {user_data.x.shape}\")\n",
    "print(f\"- Edge index shape: {user_data.edge_index.shape}\")\n",
    "print(f\"- Number of edges: {user_data.edge_index.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb125f1",
   "metadata": {},
   "source": [
    "## 6. Generate Synthetic Interaction Data\n",
    "\n",
    "Create user-POI interactions for training our recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic user-POI interactions\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create interaction matrix (users x POIs)\n",
    "n_interactions = 5000\n",
    "interactions = []\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    user_id = np.random.randint(0, n_users)\n",
    "    poi_id = np.random.randint(0, n_pois)\n",
    "    \n",
    "    # Generate rating based on user-POI compatibility\n",
    "    user_budget = users_df.iloc[user_id]['budget_preference']\n",
    "    poi_price = pois_df.iloc[poi_id]['price_level']\n",
    "    \n",
    "    # Simple compatibility scoring\n",
    "    budget_match = {\n",
    "        ('budget', '$'): 1.0, ('budget', '$$'): 0.5, ('budget', '$$$'): 0.2, ('budget', '$$$$'): 0.1,\n",
    "        ('mid-range', '$'): 0.7, ('mid-range', '$$'): 1.0, ('mid-range', '$$$'): 0.8, ('mid-range', '$$$$'): 0.3,\n",
    "        ('luxury', '$'): 0.3, ('luxury', '$$'): 0.5, ('luxury', '$$$'): 0.8, ('luxury', '$$$$'): 1.0\n",
    "    }\n",
    "    \n",
    "    base_compatibility = budget_match.get((user_budget, poi_price), 0.5)\n",
    "    \n",
    "    # Add some randomness\n",
    "    rating = np.random.normal(base_compatibility * 5, 1.0)\n",
    "    rating = np.clip(rating, 1, 5)\n",
    "    \n",
    "    interactions.append({\n",
    "        'user_id': user_id,\n",
    "        'poi_id': poi_id,\n",
    "        'rating': rating,\n",
    "        'interaction_type': np.random.choice(['view', 'book', 'review'], p=[0.6, 0.3, 0.1])\n",
    "    })\n",
    "\n",
    "interactions_df = pd.DataFrame(interactions)\n",
    "print(f\"Generated {len(interactions_df)} interactions\")\n",
    "print(interactions_df.head())\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(interactions_df['rating'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5139a2e",
   "metadata": {},
   "source": [
    "## 7. Recommendation Algorithm Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple collaborative filtering baseline\n",
    "def collaborative_filtering_recommendation(user_id, interactions_df, top_k=5):\n",
    "    \"\"\"Simple collaborative filtering recommendation\"\"\"\n",
    "    \n",
    "    # Get user's interactions\n",
    "    user_interactions = interactions_df[interactions_df['user_id'] == user_id]\n",
    "    \n",
    "    if len(user_interactions) == 0:\n",
    "        # Cold start - return popular items\n",
    "        popular_pois = interactions_df.groupby('poi_id')['rating'].mean().sort_values(ascending=False)\n",
    "        return popular_pois.head(top_k).index.tolist()\n",
    "    \n",
    "    # Find similar users based on common interactions\n",
    "    user_pois = set(user_interactions['poi_id'].tolist())\n",
    "    \n",
    "    similar_users = []\n",
    "    for other_user in interactions_df['user_id'].unique():\n",
    "        if other_user == user_id:\n",
    "            continue\n",
    "        \n",
    "        other_interactions = interactions_df[interactions_df['user_id'] == other_user]\n",
    "        other_pois = set(other_interactions['poi_id'].tolist())\n",
    "        \n",
    "        # Calculate Jaccard similarity\n",
    "        intersection = len(user_pois.intersection(other_pois))\n",
    "        union = len(user_pois.union(other_pois))\n",
    "        \n",
    "        if union > 0:\n",
    "            similarity = intersection / union\n",
    "            if similarity > 0.1:  # Threshold for similarity\n",
    "                similar_users.append((other_user, similarity))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similar_users.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get recommendations from similar users\n",
    "    recommendations = {}\n",
    "    \n",
    "    for similar_user, similarity in similar_users[:10]:  # Top 10 similar users\n",
    "        similar_interactions = interactions_df[interactions_df['user_id'] == similar_user]\n",
    "        \n",
    "        for _, interaction in similar_interactions.iterrows():\n",
    "            poi_id = interaction['poi_id']\n",
    "            rating = interaction['rating']\n",
    "            \n",
    "            # Skip POIs user has already interacted with\n",
    "            if poi_id in user_pois:\n",
    "                continue\n",
    "            \n",
    "            # Weight by similarity and rating\n",
    "            score = similarity * rating\n",
    "            \n",
    "            if poi_id in recommendations:\n",
    "                recommendations[poi_id] += score\n",
    "            else:\n",
    "                recommendations[poi_id] = score\n",
    "    \n",
    "    # Sort recommendations\n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [poi_id for poi_id, score in sorted_recommendations[:top_k]]\n",
    "\n",
    "# Test recommendation for a sample user\n",
    "test_user_id = 0\n",
    "recommendations = collaborative_filtering_recommendation(test_user_id, interactions_df)\n",
    "\n",
    "print(f\"Recommendations for user {test_user_id}:\")\n",
    "for i, poi_id in enumerate(recommendations, 1):\n",
    "    poi_info = pois_df.iloc[poi_id]\n",
    "    print(f\"{i}. POI {poi_id}: {poi_info['type']} in {poi_info['destination']} \"\n",
    "          f\"(Rating: {poi_info['rating']:.1f}, Price: {poi_info['price_level']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2df23",
   "metadata": {},
   "source": [
    "## 8. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c194f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple evaluation of recommendation system\n",
    "def evaluate_recommendations(interactions_df, n_test_users=50):\n",
    "    \"\"\"Evaluate recommendation system using simple metrics\"\"\"\n",
    "    \n",
    "    test_users = np.random.choice(interactions_df['user_id'].unique(), n_test_users, replace=False)\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    valid_users = 0\n",
    "    \n",
    "    for user_id in test_users:\n",
    "        user_interactions = interactions_df[interactions_df['user_id'] == user_id]\n",
    "        \n",
    "        if len(user_interactions) < 3:  # Need minimum interactions\n",
    "            continue\n",
    "        \n",
    "        # Split into train/test\n",
    "        train_interactions = user_interactions.iloc[:-2]  # All but last 2\n",
    "        test_interactions = user_interactions.iloc[-2:]   # Last 2 as test\n",
    "        \n",
    "        # Get recommendations based on training data\n",
    "        train_df = interactions_df[interactions_df['user_id'] != user_id]\n",
    "        train_df = pd.concat([train_df, train_interactions])\n",
    "        \n",
    "        recommendations = collaborative_filtering_recommendation(user_id, train_df, top_k=10)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_pois = set(test_interactions['poi_id'].tolist())\n",
    "        recommended_pois = set(recommendations)\n",
    "        \n",
    "        if len(recommended_pois) > 0:\n",
    "            precision = len(test_pois.intersection(recommended_pois)) / len(recommended_pois)\n",
    "            total_precision += precision\n",
    "        \n",
    "        if len(test_pois) > 0:\n",
    "            recall = len(test_pois.intersection(recommended_pois)) / len(test_pois)\n",
    "            total_recall += recall\n",
    "        \n",
    "        valid_users += 1\n",
    "    \n",
    "    if valid_users > 0:\n",
    "        avg_precision = total_precision / valid_users\n",
    "        avg_recall = total_recall / valid_users\n",
    "        f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'precision': avg_precision,\n",
    "            'recall': avg_recall,\n",
    "            'f1_score': f1_score,\n",
    "            'evaluated_users': valid_users\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Evaluate the recommendation system\n",
    "evaluation_results = evaluate_recommendations(interactions_df)\n",
    "\n",
    "if evaluation_results:\n",
    "    print(\"Recommendation System Evaluation:\")\n",
    "    print(f\"- Precision: {evaluation_results['precision']:.3f}\")\n",
    "    print(f\"- Recall: {evaluation_results['recall']:.3f}\")\n",
    "    print(f\"- F1 Score: {evaluation_results['f1_score']:.3f}\")\n",
    "    print(f\"- Users evaluated: {evaluation_results['evaluated_users']}\")\n",
    "else:\n",
    "    print(\"Unable to evaluate - insufficient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc2ee3",
   "metadata": {},
   "source": [
    "## 9. Next Steps for GNN Implementation\n",
    "\n",
    "This notebook provides a foundation for GNN-based travel recommendations. Next steps include:\n",
    "\n",
    "1. **Enhanced GNN Architecture**:\n",
    "   - Implement attention mechanisms\n",
    "   - Add graph pooling layers\n",
    "   - Multi-layer graph convolutions\n",
    "\n",
    "2. **Real Data Integration**:\n",
    "   - Connect to actual travel APIs\n",
    "   - Process real user interaction data\n",
    "   - Incorporate temporal dynamics\n",
    "\n",
    "3. **Advanced Features**:\n",
    "   - Heterogeneous graphs (users, POIs, destinations)\n",
    "   - Dynamic graph updates\n",
    "   - Multi-modal embeddings\n",
    "\n",
    "4. **Production Integration**:\n",
    "   - Model serving infrastructure\n",
    "   - Real-time inference\n",
    "   - A/B testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for use in the main application\n",
    "results = {\n",
    "    'user_similarity_matrix': user_similarity,\n",
    "    'poi_similarity_matrix': poi_similarity,\n",
    "    'user_features': user_features_scaled,\n",
    "    'poi_features': poi_features_scaled,\n",
    "    'interactions': interactions_df,\n",
    "    'evaluation_metrics': evaluation_results\n",
    "}\n",
    "\n",
    "print(\"\\n✅ GNN Research Notebook Complete!\")\n",
    "print(\"\\nKey findings:\")\n",
    "print(f\"- Built user similarity graph with {user_graph.number_of_edges()} connections\")\n",
    "print(f\"- Built POI relationship graph with {poi_graph.number_of_edges()} connections\")\n",
    "print(f\"- Generated {len(interactions_df)} user-POI interactions\")\n",
    "if evaluation_results:\n",
    "    print(f\"- Achieved F1 score of {evaluation_results['f1_score']:.3f} on recommendation task\")\n",
    "print(\"\\nNext: Integrate these findings into the main AI Travel Planner application!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
